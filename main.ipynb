{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishika-Garg/fedlearning-under-attack/blob/main/Minor_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision, flwr, numpy\n",
        "print(torch.__version__, torchvision.__version__, numpy.__version__, flwr.__version__)\n"
      ],
      "metadata": {
        "id": "MlMX1BQgsLUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir torch==2.2.0 torchvision==0.17.0 flwr==1.3.0"
      ],
      "metadata": {
        "id": "AoxbdsrjsX-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLiVQ3SnZz0T"
      },
      "outputs": [],
      "source": [
        "# Install Flower + PyTorch + torchvision and pin numpy to avoid binary conflicts\n",
        "# Clean up any corrupted installs\n",
        "!pip uninstall -y numpy torch torchvision flwr || true\n",
        "\n",
        "# Reinstall in the safest order (avoid cache conflicts)\n",
        "!pip install --no-cache-dir numpy==1.26.4\n",
        "!pip install --no-cache-dir torch==2.2.0 torchvision==0.17.0\n",
        "!pip install --no-cache-dir flwr==1.3.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3nWZGT-zwYH"
      },
      "outputs": [],
      "source": [
        "# Run this as a single Colab cell. It installs numpy first (to avoid binary mismatch),\n",
        "# then PyTorch + torchvision, then Flower. --no-cache-dir helps avoid cached wheels.\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade --force-reinstall --no-cache-dir numpy==1.26.4\n",
        "!pip install --upgrade --force-reinstall --no-cache-dir torch torchvision\n",
        "!pip install --upgrade --force-reinstall --no-cache-dir flwr==1.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_iX2eI-aQVj"
      },
      "outputs": [],
      "source": [
        "# Download MNIST and partition equally into 10 client loaders (IID)\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "testset  = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "print(f\"Train samples: {len(trainset)}, Test samples: {len(testset)}\")\n",
        "\n",
        "num_clients = 10\n",
        "data_per_client = len(trainset) // num_clients\n",
        "\n",
        "client_indices = [list(range(i*data_per_client, (i+1)*data_per_client)) for i in range(num_clients)]\n",
        "client_loaders = [ DataLoader(Subset(trainset, idxs), batch_size=32, shuffle=True) for idxs in client_indices ]\n",
        "\n",
        "testloader = DataLoader(testset, batch_size=256, shuffle=False)\n",
        "\n",
        "# verify one batch\n",
        "images, labels = next(iter(client_loaders[0]))\n",
        "print(\"One client batch shape:\", images.shape)\n",
        "print(\"Sample labels:\", labels[:10].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2RHQSCGa0TS"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # conv layers\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, 1)   # 28x28 -> 26x26\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1)  # 26x26 -> 24x24\n",
        "        self.pool  = nn.MaxPool2d(2, 2)       # 24x24 -> 12x12\n",
        "        # flatten size after pooling = 32 * 12 * 12\n",
        "        self.fc1   = nn.Linear(32 * 12 * 12, 128)\n",
        "        self.fc2   = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# quick test forward pass\n",
        "model = Net()\n",
        "sample_images, _ = next(iter(client_loaders[0]))\n",
        "output = model(sample_images)   # should not error\n",
        "print(\"Model forward output shape:\", output.shape)  # expect [batch_size, 10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3Ei0nIl0jds"
      },
      "outputs": [],
      "source": [
        "# Optional: quick one-batch train step to confirm backprop works\n",
        "import torch.optim as optim\n",
        "model.train()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "x, y = next(iter(client_loaders[0]))\n",
        "optimizer.zero_grad()\n",
        "out = model(x)\n",
        "loss = F.cross_entropy(out, y)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "print(\"One minibatch training step OK. Loss:\", loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZli768r0j2U"
      },
      "outputs": [],
      "source": [
        "import flwr as fl\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from typing import List, Tuple, Dict\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkRZ7Npq07N8"
      },
      "outputs": [],
      "source": [
        "def get_weights(model: torch.nn.Module) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
        "\n",
        "def set_weights(model: torch.nn.Module, weights: List[np.ndarray]) -> None:\n",
        "    params_dict = zip(model.state_dict().keys(), weights)\n",
        "    state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
        "    model.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8de--dR09nR"
      },
      "outputs": [],
      "source": [
        "class FLClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid: int, model: torch.nn.Module, trainloader, testloader):\n",
        "        self.cid = cid\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return get_weights(self.model)\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        set_weights(self.model, parameters)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Set incoming global weights\n",
        "        self.set_parameters(parameters)\n",
        "        # Local training (1 epoch default; can be changed via config)\n",
        "        self.model.train()\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
        "        local_epochs = int(config.get(\"local_epochs\", 1))\n",
        "        for _ in range(local_epochs):\n",
        "            for x, y in self.trainloader:\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                out = self.model(x)\n",
        "                loss = F.cross_entropy(out, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        # Return updated weights and number of examples\n",
        "        return self.get_parameters(), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        # Evaluate on local test data (we return metrics, but server can also run a global evaluation)\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in self.testloader:\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                out = self.model(x)\n",
        "                loss += F.cross_entropy(out, y).item() * x.size(0)\n",
        "                preds = out.argmax(dim=1)\n",
        "                correct += (preds == y).sum().item()\n",
        "                total += x.size(0)\n",
        "        if total == 0:\n",
        "            return float(loss), 0, {}\n",
        "        return float(loss / total), total, {\"accuracy\": float(correct / total)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUSKg5l11Aqq"
      },
      "outputs": [],
      "source": [
        "def server_evaluate(weights: List[np.ndarray]) -> Tuple[float, Dict[str, float]]:\n",
        "    \"\"\"Given global weights, set them on a fresh model and evaluate on the global test set.\"\"\"\n",
        "    model = Net()\n",
        "    set_weights(model, weights)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in testloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            loss += F.cross_entropy(out, y).item() * x.size(0)\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += x.size(0)\n",
        "    if total == 0:\n",
        "        return None\n",
        "    return float(loss / total), {\"accuracy\": float(correct / total)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA5KsCiY1DEU"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FLClient:\n",
        "    # Each client gets its own fresh model instance and its respective DataLoader\n",
        "    idx = int(cid)\n",
        "    model = Net()\n",
        "    trainloader = client_loaders[idx]\n",
        "    # Use shared global testloader here for simplicity (local evaluate uses same test)\n",
        "    return FLClient(cid=idx, model=model, trainloader=trainloader, testloader=testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIwIH1F01E9k"
      },
      "outputs": [],
      "source": [
        "# --- Manual FedAvg simulation (no Flower / no Ray) ---\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Config\n",
        "NUM_ROUNDS = 5\n",
        "LOCAL_EPOCHS = 1\n",
        "lr = 0.01\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Helper: local train that returns updated model weights (numpy) and number of examples\n",
        "def local_train_return_weights(model, trainloader, global_weights, local_epochs=1, lr=0.01):\n",
        "    # set global weights\n",
        "    set_weights(model, global_weights)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    for _ in range(local_epochs):\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = F.cross_entropy(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    # return numpy weights and count\n",
        "    return get_weights(model), len(trainloader.dataset)\n",
        "\n",
        "# Helper: evaluate a model (PyTorch model instance) on testloader, returns accuracy\n",
        "def evaluate_model_on_test(model):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in testloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += x.size(0)\n",
        "    return correct / total if total > 0 else 0.0\n",
        "\n",
        "# Initialize global model (fresh)\n",
        "global_model = Net().to(device)\n",
        "global_weights = get_weights(global_model)\n",
        "\n",
        "print(\"Starting manual FedAvg simulation: {} clients, {} rounds, {} local epochs\".format(len(client_loaders), NUM_ROUNDS, LOCAL_EPOCHS))\n",
        "\n",
        "for rnd in range(1, NUM_ROUNDS + 1):\n",
        "    client_updates = []\n",
        "    client_ns = []\n",
        "    # Each client trains locally and returns updated weights\n",
        "    for i, trainloader in enumerate(client_loaders):\n",
        "        local_model = Net()  # fresh model instance for the client\n",
        "        w, n = local_train_return_weights(local_model, trainloader, global_weights, local_epochs=LOCAL_EPOCHS, lr=lr)\n",
        "        client_updates.append(w)\n",
        "        client_ns.append(n)\n",
        "    # Federated averaging (weighted by number of examples)\n",
        "    # compute total examples\n",
        "    total_n = sum(client_ns)\n",
        "    # initialize averaged weights as zeros arrays with same shapes\n",
        "    avg_weights = []\n",
        "    for layer_idx in range(len(client_updates[0])):\n",
        "        # start with zeros of same shape\n",
        "        layer_shape = client_updates[0][layer_idx].shape\n",
        "        accum = np.zeros(layer_shape, dtype=client_updates[0][layer_idx].dtype)\n",
        "        # add weighted contributions\n",
        "        for c_idx in range(len(client_updates)):\n",
        "            accum += client_updates[c_idx][layer_idx] * (client_ns[c_idx] / total_n)\n",
        "        avg_weights.append(accum)\n",
        "    # set new global weights\n",
        "    global_weights = avg_weights\n",
        "    set_weights(global_model, global_weights)\n",
        "\n",
        "    # Evaluate global model on test set\n",
        "    acc = evaluate_model_on_test(global_model)\n",
        "    print(f\"Round {rnd:02d} -> Global test accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "print(\"Manual FedAvg simulation finished.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dda962e0"
      },
      "outputs": [],
      "source": [
        "!pip install -U \"flwr[simulation]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Su-wHht1IPK"
      },
      "outputs": [],
      "source": [
        "# Quick import test: is Flower and Ray available?\n",
        "import importlib, sys\n",
        "results = {}\n",
        "for pkg in (\"flwr\", \"ray\"):\n",
        "    try:\n",
        "        mod = importlib.import_module(pkg)\n",
        "        results[pkg] = f\"OK, version {getattr(mod, '__version__', 'unknown')}\"\n",
        "    except Exception as e:\n",
        "        results[pkg] = f\"IMPORT ERROR: {type(e).__name__}: {e}\"\n",
        "\n",
        "for k,v in results.items():\n",
        "    print(k, \"=>\", v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etqTxlfI1ikn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNKVlYlL2-WH"
      },
      "outputs": [],
      "source": [
        "NUM_ROUNDS = 5\n",
        "LOCAL_EPOCHS = 1\n",
        "lr = 0.01\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Choose attacker clients (indices in 0..num_clients-1). Example: client 0 is malicious.\n",
        "malicious_client_ids = {0}            # set of malicious client indices\n",
        "attack_type = \"label_flip\"            # currently only label_flip implemented\n",
        "# Label-flip specifics: source_label -> target_label (we measure ASR for source->target)\n",
        "source_label = 0\n",
        "target_label = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ur33Z-B3BSA"
      },
      "outputs": [],
      "source": [
        "def local_train_return_weights(model, trainloader, global_weights, local_epochs=1, lr=0.01, is_malicious=False):\n",
        "    set_weights(model, global_weights)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    for _ in range(local_epochs):\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            # If malicious and attack_type is label_flip, flip labels in the local batch\n",
        "            if is_malicious and attack_type == \"label_flip\":\n",
        "                # Simple flip: map source_label -> target_label, keep others unchanged\n",
        "                # If you want full class shift (y+1)%10, replace line below accordingly.\n",
        "                mask = (y == source_label)\n",
        "                if mask.any():\n",
        "                    y[mask] = target_label\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = F.cross_entropy(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return get_weights(model), len(trainloader.dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSbf65wv3D8s"
      },
      "outputs": [],
      "source": [
        "def compute_asr(model):\n",
        "    \"\"\"ASR = fraction of test samples whose true label==source_label but predicted==target_label\"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    total_source = 0\n",
        "    source_to_target = 0\n",
        "    for x, y in testloader:\n",
        "        mask = (y == source_label)\n",
        "        if not mask.any():\n",
        "            continue\n",
        "        x_src = x[mask].to(device)\n",
        "        y_src = y[mask].to(device)\n",
        "        out = model(x_src)\n",
        "        preds = out.argmax(dim=1)\n",
        "        total_source += y_src.size(0)\n",
        "        source_to_target += (preds == target_label).sum().item()\n",
        "    return (source_to_target / total_source) if total_source > 0 else 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFfcE-H73GNM"
      },
      "outputs": [],
      "source": [
        "global_model = Net().to(device)\n",
        "global_weights = get_weights(global_model)\n",
        "\n",
        "acc_history = []\n",
        "asr_history = []\n",
        "\n",
        "print(f\"Running FedAvg with malicious clients {malicious_client_ids} (attack={attack_type})\")\n",
        "for rnd in range(1, NUM_ROUNDS + 1):\n",
        "    client_updates = []\n",
        "    client_ns = []\n",
        "    for i, trainloader in enumerate(client_loaders):\n",
        "        local_model = Net()\n",
        "        is_mal = (i in malicious_client_ids)\n",
        "        w, n = local_train_return_weights(local_model, trainloader, global_weights,\n",
        "                                          local_epochs=LOCAL_EPOCHS, lr=lr, is_malicious=is_mal)\n",
        "        client_updates.append(w)\n",
        "        client_ns.append(n)\n",
        "    # weighted average\n",
        "    total_n = sum(client_ns)\n",
        "    avg_weights = []\n",
        "    for layer_idx in range(len(client_updates[0])):\n",
        "        accum = np.zeros(client_updates[0][layer_idx].shape, dtype=client_updates[0][layer_idx].dtype)\n",
        "        for c_idx in range(len(client_updates)):\n",
        "            accum += client_updates[c_idx][layer_idx] * (client_ns[c_idx] / total_n)\n",
        "        avg_weights.append(accum)\n",
        "    global_weights = avg_weights\n",
        "    set_weights(global_model, global_weights)\n",
        "\n",
        "    # evaluate\n",
        "    # global accuracy on clean test set\n",
        "    global_model.to(device)\n",
        "    global_model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in testloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = global_model(x)\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += x.size(0)\n",
        "    acc = correct / total if total > 0 else 0.0\n",
        "    asr = compute_asr(global_model)\n",
        "\n",
        "    acc_history.append(acc)\n",
        "    asr_history.append(asr)\n",
        "\n",
        "    print(f\"Round {rnd:02d} -> Global accuracy: {acc*100:.2f}%, ASR (#{source_label}->{target_label}): {asr*100:.2f}%\")\n",
        "\n",
        "print(\"Finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZD72t6m3JNF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(range(1, NUM_ROUNDS+1), [a*100 for a in acc_history], marker='o', label='Global Accuracy')\n",
        "plt.plot(range(1, NUM_ROUNDS+1), [a*100 for a in asr_history], marker='x', label=f'ASR {source_label}->{target_label}')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Percent')\n",
        "plt.title('FedAvg: Accuracy and ASR over Rounds')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MqkHzX83w9W"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "# show label distribution per client\n",
        "for i, loader in enumerate(client_loaders):\n",
        "    labels = []\n",
        "    for _, y in loader:\n",
        "        labels.extend(y.tolist())\n",
        "    c = Counter(labels)\n",
        "    print(f\"Client {i}: total={sum(c.values())}, label_counts={dict(c)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJU3Fty030ZN"
      },
      "outputs": [],
      "source": [
        "# CELL A — Label-flip grid experiments\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import copy\n",
        "from itertools import product\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Experiment config (tweak)\n",
        "NUM_ROUNDS = 5\n",
        "LOCAL_EPOCHS = 1\n",
        "ATTACKER_LOCAL_EPOCHS = 5\n",
        "lr = 0.01\n",
        "\n",
        "# grid to try\n",
        "attacker_fractions = [0.1, 0.3]   # e.g., 10% and 30% attackers\n",
        "flip_modes = [\"single\", \"full\"]    # single: only source->target, full: y -> (y+1)%10\n",
        "scale_options = [False, True]      # whether to scale malicious deltas\n",
        "scale_factor = 5.0\n",
        "\n",
        "# target/source for ASR when using \"single\"\n",
        "source_label = 0\n",
        "target_label = 1\n",
        "\n",
        "# helpers (re-used)\n",
        "def local_train_return_weights(model, trainloader, global_weights, local_epochs=1, lr=0.01, is_malicious=False, flip_mode=\"single\"):\n",
        "    set_weights(model, global_weights)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    for _ in range(local_epochs):\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            if is_malicious:\n",
        "                if flip_mode == \"single\":\n",
        "                    mask = (y == source_label)\n",
        "                    if mask.any():\n",
        "                        y[mask] = target_label\n",
        "                else:  # full\n",
        "                    y = (y + 1) % 10\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = F.cross_entropy(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return get_weights(model), len(trainloader.dataset)\n",
        "\n",
        "def scale_update(client_w, global_w, scale):\n",
        "    scaled = []\n",
        "    for cw, gw in zip(client_w, global_w):\n",
        "        delta = cw - gw\n",
        "        scaled.append(gw + scale * delta)\n",
        "    return scaled\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_asr(model, src=0, tgt=1):\n",
        "    model.to(device); model.eval()\n",
        "    total_source = 0; source_to_target = 0\n",
        "    for x, y in testloader:\n",
        "        mask = (y == src)\n",
        "        if not mask.any(): continue\n",
        "        x_src = x[mask].to(device); y_src = y[mask].to(device)\n",
        "        out = model(x_src); preds = out.argmax(dim=1)\n",
        "        total_source += y_src.size(0)\n",
        "        source_to_target += (preds == tgt).sum().item()\n",
        "    return (source_to_target / total_source) if total_source > 0 else 0.0\n",
        "\n",
        "def evaluate_global(model):\n",
        "    model.to(device); model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in testloader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            out = model(x); preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item(); total += x.size(0)\n",
        "    return correct / total if total > 0 else 0.0\n",
        "\n",
        "# Run grid\n",
        "results = []\n",
        "num_clients = len(client_loaders)\n",
        "client_indices = list(range(num_clients))\n",
        "\n",
        "for frac, flip_mode, scale in product(attacker_fractions, flip_modes, scale_options):\n",
        "    k_attackers = max(1, int(round(frac * num_clients)))\n",
        "    # choose first k_attackers clients as malicious (deterministic)\n",
        "    malicious_ids = set(client_indices[:k_attackers])\n",
        "    print(f\"\\nRunning config: frac={frac}, k={k_attackers}, flip_mode={flip_mode}, scale={scale}\")\n",
        "    # Initialize global model\n",
        "    global_model = Net().to(device)\n",
        "    global_weights = get_weights(global_model)\n",
        "    acc_history = []; asr_history = []\n",
        "    for rnd in range(1, NUM_ROUNDS+1):\n",
        "        client_updates = []; client_ns = []\n",
        "        for i, trainloader in enumerate(client_loaders):\n",
        "            local_model = Net()\n",
        "            is_mal = (i in malicious_ids)\n",
        "            local_epochs = ATTACKER_LOCAL_EPOCHS if is_mal else LOCAL_EPOCHS\n",
        "            w, n = local_train_return_weights(local_model, trainloader, global_weights,\n",
        "                                              local_epochs=local_epochs, lr=lr, is_malicious=is_mal, flip_mode=flip_mode)\n",
        "            if is_mal and scale:\n",
        "                w = scale_update(w, global_weights, scale_factor)\n",
        "            client_updates.append(w); client_ns.append(n)\n",
        "        # FedAvg average\n",
        "        total_n = sum(client_ns)\n",
        "        avg_weights = []\n",
        "        for li in range(len(client_updates[0])):\n",
        "            accum = np.zeros(client_updates[0][li].shape, dtype=client_updates[0][li].dtype)\n",
        "            for ci in range(len(client_updates)):\n",
        "                accum += client_updates[ci][li] * (client_ns[ci] / total_n)\n",
        "            avg_weights.append(accum)\n",
        "        global_weights = avg_weights\n",
        "        set_weights(global_model, global_weights)\n",
        "        acc = evaluate_global(global_model)\n",
        "        asr = compute_asr(global_model, src=source_label, tgt=target_label)\n",
        "        acc_history.append(acc); asr_history.append(asr)\n",
        "        print(f\"Round {rnd} -> acc {acc*100:.2f}%, ASR {asr*100:.2f}%\")\n",
        "    results.append({\n",
        "        \"attacker_frac\": frac,\n",
        "        \"k_attackers\": k_attackers,\n",
        "        \"flip_mode\": flip_mode,\n",
        "        \"scale\": scale,\n",
        "        \"round_1_acc\": acc_history[0],\n",
        "        \"round_final_acc\": acc_history[-1],\n",
        "        \"round_1_asr\": asr_history[0],\n",
        "        \"round_final_asr\": asr_history[-1],\n",
        "        \"acc_series\": acc_history,\n",
        "        \"asr_series\": asr_history\n",
        "    })\n",
        "\n",
        "# Save summary CSV (flatten basic results)\n",
        "df = pd.DataFrame([{\n",
        "    \"attacker_frac\": r[\"attacker_frac\"],\n",
        "    \"k_attackers\": r[\"k_attackers\"],\n",
        "    \"flip_mode\": r[\"flip_mode\"],\n",
        "    \"scale\": r[\"scale\"],\n",
        "    \"final_acc\": r[\"round_final_acc\"],\n",
        "    \"final_asr\": r[\"round_final_asr\"]\n",
        "} for r in results])\n",
        "df.to_csv(\"results_labelflip_summary.csv\", index=False)\n",
        "print(\"\\nSaved results_labelflip_summary.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_2raGgy5LxG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"results_labelflip_summary.csv\")\n",
        "display(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_Uf4Pze-Go_"
      },
      "outputs": [],
      "source": [
        "# CELL B — Backdoor attack (visual trigger) experiment (paste & run)\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from copy import deepcopy\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Config (tweak if you want)\n",
        "NUM_ROUNDS = 5\n",
        "LOCAL_EPOCHS = 1\n",
        "ATTACKER_LOCAL_EPOCHS = 5\n",
        "lr = 0.01\n",
        "malicious_client_ids = {0, 1}   # attacker clients (change as needed)\n",
        "target_label = 7                # the label attacker wants triggered inputs to be classified as\n",
        "poison_frac = 0.2               # fraction of local mini-batch attacker poisons\n",
        "\n",
        "# Trigger function: add a small white square in bottom-right of the image\n",
        "def add_trigger_batch(x_batch, size=4, value=1.0):\n",
        "    x = x_batch.clone()\n",
        "    b, c, h, w = x.shape\n",
        "    x[:, :, h-size:h, w-size:w] = value\n",
        "    return x\n",
        "\n",
        "# Build a triggered test set (trigger applied to all test images)\n",
        "triggered_inputs = []\n",
        "triggered_labels = []\n",
        "for x, y in testloader:\n",
        "    xt = add_trigger_batch(x, size=4, value=1.0)\n",
        "    triggered_inputs.append(xt)\n",
        "    triggered_labels.append(y)\n",
        "triggered_X = torch.cat(triggered_inputs, dim=0)\n",
        "triggered_Y = torch.cat(triggered_labels, dim=0)\n",
        "print(\"Triggered test built:\", triggered_X.shape, triggered_Y.shape)\n",
        "\n",
        "# Local training for backdoor (attackers poison a fraction of their batches)\n",
        "def local_train_backdoor(model, trainloader, global_weights, local_epochs=1, lr=0.01, is_malicious=False, poison_frac=0.2):\n",
        "    set_weights(model, global_weights)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    for _ in range(local_epochs):\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            if is_malicious:\n",
        "                B = x.size(0)\n",
        "                k = max(1, int(round(poison_frac * B)))\n",
        "                idx = torch.randperm(B)[:k]\n",
        "                x[idx] = add_trigger_batch(x[idx], size=4, value=1.0)\n",
        "                y[idx] = target_label\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = F.cross_entropy(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return get_weights(model), len(trainloader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_asr_backdoor(model):\n",
        "    model.to(device); model.eval()\n",
        "    correct_target = 0; total = 0\n",
        "    batch_size = 256\n",
        "    for i in range(0, len(triggered_X), batch_size):\n",
        "        xb = triggered_X[i:i+batch_size].to(device)\n",
        "        out = model(xb)\n",
        "        preds = out.argmax(dim=1)\n",
        "        total += preds.size(0)\n",
        "        correct_target += (preds == target_label).sum().item()\n",
        "    return correct_target / total if total > 0 else 0.0\n",
        "\n",
        "def evaluate_global(model):\n",
        "    model.to(device); model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in testloader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            out = model(x); preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item(); total += x.size(0)\n",
        "    return correct / total if total > 0 else 0.0\n",
        "\n",
        "# Run FedAvg with the backdoor attackers\n",
        "global_model = Net().to(device)\n",
        "global_weights = get_weights(global_model)\n",
        "\n",
        "print(\"Starting backdoor experiment: attackers:\", malicious_client_ids, \"target_label:\", target_label)\n",
        "for rnd in range(1, NUM_ROUNDS+1):\n",
        "    client_updates = []; client_ns = []\n",
        "    for i, trainloader in enumerate(client_loaders):\n",
        "        local_model = Net()\n",
        "        is_mal = (i in malicious_client_ids)\n",
        "        local_epochs = ATTACKER_LOCAL_EPOCHS if is_mal else LOCAL_EPOCHS\n",
        "        w, n = local_train_backdoor(local_model, trainloader, global_weights,\n",
        "                                    local_epochs=local_epochs, lr=lr, is_malicious=is_mal, poison_frac=poison_frac)\n",
        "        client_updates.append(w); client_ns.append(n)\n",
        "    # FedAvg average\n",
        "    total_n = sum(client_ns)\n",
        "    avg_weights = []\n",
        "    for li in range(len(client_updates[0])):\n",
        "        accum = np.zeros(client_updates[0][li].shape, dtype=client_updates[0][li].dtype)\n",
        "        for ci in range(len(client_updates)):\n",
        "            accum += client_updates[ci][li] * (client_ns[ci] / total_n)\n",
        "        avg_weights.append(accum)\n",
        "    global_weights = avg_weights\n",
        "    set_weights(global_model, global_weights)\n",
        "\n",
        "    acc = evaluate_global(global_model)\n",
        "    asr_b = compute_asr_backdoor(global_model)\n",
        "    print(f\"Round {rnd} -> Global acc: {acc*100:.2f}%, Backdoor ASR -> target {target_label}: {asr_b*100:.2f}%\")\n",
        "\n",
        "print(\"Backdoor experiment finished.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvJWQwo--gae"
      },
      "outputs": [],
      "source": [
        "# CELL C — Defenses: Trimmed Mean and Krum vs Baseline (backdoor scenario)\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from copy import deepcopy\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- Config (matches your last backdoor experiment) ----------\n",
        "NUM_ROUNDS = 5\n",
        "LOCAL_EPOCHS = 1\n",
        "ATTACKER_LOCAL_EPOCHS = 5\n",
        "lr = 0.01\n",
        "malicious_client_ids = {0, 1}\n",
        "target_label = 7\n",
        "poison_frac = 0.2\n",
        "\n",
        "# ---------- Aggregator functions ----------\n",
        "def trimmed_mean_aggregate(client_updates, trim_ratio=0.2):\n",
        "    n_clients = len(client_updates)\n",
        "    trimmed = []\n",
        "    for layer_idx in range(len(client_updates[0])):\n",
        "        # stack per client for this layer\n",
        "        stacked = np.stack([client_updates[c][layer_idx].reshape(-1) for c in range(n_clients)], axis=0)  # (n_clients, N)\n",
        "        trim_count = int(np.floor(trim_ratio * n_clients))\n",
        "        sorted_vals = np.sort(stacked, axis=0)\n",
        "        if trim_count > 0:\n",
        "            trimmed_vals = sorted_vals[trim_count: n_clients-trim_count, :]\n",
        "        else:\n",
        "            trimmed_vals = sorted_vals\n",
        "        mean_vals = np.mean(trimmed_vals, axis=0)\n",
        "        avg_layer = mean_vals.reshape(client_updates[0][layer_idx].shape)\n",
        "        trimmed.append(avg_layer)\n",
        "    return trimmed\n",
        "\n",
        "def krum_aggregate(client_updates, f=1):\n",
        "    n = len(client_updates)\n",
        "    if n <= 2*f + 2:\n",
        "        raise ValueError(\"Not enough clients for Krum with f={} (need n > 2f+2)\".format(f))\n",
        "    # flatten\n",
        "    flat = [np.concatenate([layer.reshape(-1) for layer in client_updates[c]]) for c in range(n)]\n",
        "    dists = np.zeros((n,n))\n",
        "    for i in range(n):\n",
        "        for j in range(i+1,n):\n",
        "            d = np.sum((flat[i] - flat[j])**2)\n",
        "            dists[i,j] = d; dists[j,i] = d\n",
        "    scores = []\n",
        "    for i in range(n):\n",
        "        sorted_d = np.sort(dists[i])\n",
        "        nb_count = n - f - 2\n",
        "        # sum of smallest nb_count distances (exclude its own zero at sorted_d[0])\n",
        "        score = np.sum(sorted_d[1:1+nb_count])\n",
        "        scores.append(score)\n",
        "    winner = int(np.argmin(scores))\n",
        "    # return the chosen client's update (Krum selects a single update)\n",
        "    return client_updates[winner]\n",
        "\n",
        "# ---------- Backdoor local training used earlier ----------\n",
        "def add_trigger_batch(x_batch, size=4, value=1.0):\n",
        "    x = x_batch.clone()\n",
        "    b, c, h, w = x.shape\n",
        "    x[:, :, h-size:h, w-size:w] = value\n",
        "    return x\n",
        "\n",
        "def local_train_backdoor(model, trainloader, global_weights, local_epochs=1, lr=0.01, is_malicious=False, poison_frac=0.2):\n",
        "    set_weights(model, global_weights)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    for _ in range(local_epochs):\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            if is_malicious:\n",
        "                B = x.size(0)\n",
        "                k = max(1, int(round(poison_frac * B)))\n",
        "                idx = torch.randperm(B)[:k]\n",
        "                x[idx] = add_trigger_batch(x[idx], size=4, value=1.0)\n",
        "                y[idx] = target_label\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = F.cross_entropy(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return get_weights(model), len(trainloader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_asr_backdoor(model):\n",
        "    model.to(device); model.eval()\n",
        "    correct_target = 0; total = 0\n",
        "    batch_size = 256\n",
        "    for i in range(0, len(triggered_X), batch_size):\n",
        "        xb = triggered_X[i:i+batch_size].to(device)\n",
        "        out = model(xb)\n",
        "        preds = out.argmax(dim=1)\n",
        "        total += preds.size(0)\n",
        "        correct_target += (preds == target_label).sum().item()\n",
        "    return correct_target / total if total > 0 else 0.0\n",
        "\n",
        "def evaluate_global(model):\n",
        "    model.to(device); model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in testloader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            out = model(x); preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item(); total += x.size(0)\n",
        "    return correct / total if total > 0 else 0.0\n",
        "\n",
        "# ---------- Helper to run one experiment with chosen aggregator ----------\n",
        "def run_backdoor_with_aggregator(aggregator_name=\"fedavg\", trim_ratio=0.2, krum_f=1):\n",
        "    print(\"\\n=== Running with aggregator:\", aggregator_name, \"===\")\n",
        "    global_model = Net().to(device)\n",
        "    global_weights = get_weights(global_model)\n",
        "    acc_history = []; asr_history = []\n",
        "    for rnd in range(1, NUM_ROUNDS+1):\n",
        "        client_updates = []; client_ns = []\n",
        "        for i, trainloader in enumerate(client_loaders):\n",
        "            local_model = Net()\n",
        "            is_mal = (i in malicious_client_ids)\n",
        "            local_epochs = ATTACKER_LOCAL_EPOCHS if is_mal else LOCAL_EPOCHS\n",
        "            w, n = local_train_backdoor(local_model, trainloader, global_weights,\n",
        "                                        local_epochs=local_epochs, lr=lr, is_malicious=is_mal, poison_frac=poison_frac)\n",
        "            client_updates.append(w); client_ns.append(n)\n",
        "        # Aggregate\n",
        "        if aggregator_name == \"fedavg\":\n",
        "            total_n = sum(client_ns)\n",
        "            avg_weights = []\n",
        "            for li in range(len(client_updates[0])):\n",
        "                accum = np.zeros(client_updates[0][li].shape, dtype=client_updates[0][li].dtype)\n",
        "                for ci in range(len(client_updates)):\n",
        "                    accum += client_updates[ci][li] * (client_ns[ci] / total_n)\n",
        "                avg_weights.append(accum)\n",
        "        elif aggregator_name == \"trimmed_mean\":\n",
        "            avg_weights = trimmed_mean_aggregate(client_updates, trim_ratio=trim_ratio)\n",
        "        elif aggregator_name == \"krum\":\n",
        "            avg_weights = krum_aggregate(client_updates, f=krum_f)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown aggregator\")\n",
        "        global_weights = avg_weights\n",
        "        set_weights(global_model, global_weights)\n",
        "        acc = evaluate_global(global_model)\n",
        "        asr_b = compute_asr_backdoor(global_model)\n",
        "        acc_history.append(acc); asr_history.append(asr_b)\n",
        "        print(f\"Round {rnd} -> acc: {acc*100:.2f}%, Backdoor ASR: {asr_b*100:.2f}%\")\n",
        "    return acc_history, asr_history\n",
        "\n",
        "# ---------- Run baseline, trimmed mean, and krum ----------\n",
        "# Ensure triggered_X / triggered_Y exist from your previous Cell B run (they should)\n",
        "# If not present, you must rebuild triggered_X as in Cell B before running this cell.\n",
        "try:\n",
        "    _ = triggered_X.shape\n",
        "except NameError:\n",
        "    raise RuntimeError(\"triggered_X not found. Run Cell B (backdoor) first to build triggered test set.\")\n",
        "\n",
        "# FedAvg baseline\n",
        "acc_b, asr_b = run_backdoor_with_aggregator(\"fedavg\")\n",
        "\n",
        "# Trimmed Mean\n",
        "acc_t, asr_t = run_backdoor_with_aggregator(\"trimmed_mean\", trim_ratio=0.2)\n",
        "\n",
        "# Krum (choose f = number of suspected Byzantine clients; here f=2 for 2 attackers)\n",
        "acc_k, asr_k = run_backdoor_with_aggregator(\"krum\", krum_f=2)\n",
        "\n",
        "print(\"\\nFinished defense experiments. Summary (final round):\")\n",
        "print(f\"FedAvg -> acc {acc_b[-1]*100:.2f}%, ASR {asr_b[-1]*100:.2f}%\")\n",
        "print(f\"TrimmedMean -> acc {acc_t[-1]*100:.2f}%, ASR {asr_t[-1]*100:.2f}%\")\n",
        "print(f\"Krum -> acc {acc_k[-1]*100:.2f}%, ASR {asr_k[-1]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKdjrgHV_eda"
      },
      "outputs": [],
      "source": [
        "# Trim sweep + simple FoolsGold aggregator (paste-run)\n",
        "import numpy as np\n",
        "import torch, torch.nn.functional as F\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Experiment config (matches your earlier backdoor run)\n",
        "NUM_ROUNDS = 5\n",
        "LOCAL_EPOCHS = 1\n",
        "ATTACKER_LOCAL_EPOCHS = 5\n",
        "lr = 0.01\n",
        "malicious_client_ids = {0,1}\n",
        "target_label = 7\n",
        "poison_frac = 0.2\n",
        "\n",
        "# Use same local_train_backdoor from earlier (redefine if necessary)\n",
        "def add_trigger_batch(x_batch, size=4, value=1.0):\n",
        "    x = x_batch.clone()\n",
        "    b, c, h, w = x.shape\n",
        "    x[:, :, h-size:h, w-size:w] = value\n",
        "    return x\n",
        "\n",
        "def local_train_backdoor(model, trainloader, global_weights, local_epochs=1, lr=0.01, is_malicious=False, poison_frac=0.2):\n",
        "    set_weights(model, global_weights)\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    for _ in range(local_epochs):\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            if is_malicious:\n",
        "                B = x.size(0)\n",
        "                k = max(1, int(round(poison_frac * B)))\n",
        "                idx = torch.randperm(B)[:k]\n",
        "                x[idx] = add_trigger_batch(x[idx], size=4, value=1.0)\n",
        "                y[idx] = target_label\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = F.cross_entropy(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return get_weights(model), len(trainloader.dataset)\n",
        "\n",
        "# Evaluate helpers\n",
        "@torch.no_grad()\n",
        "def compute_asr_backdoor(model):\n",
        "    model.to(device); model.eval()\n",
        "    correct_target = 0; total = 0\n",
        "    batch_size = 256\n",
        "    for i in range(0, len(triggered_X), batch_size):\n",
        "        xb = triggered_X[i:i+batch_size].to(device)\n",
        "        out = model(xb)\n",
        "        preds = out.argmax(dim=1)\n",
        "        total += preds.size(0)\n",
        "        correct_target += (preds == target_label).sum().item()\n",
        "    return correct_target / total if total > 0 else 0.0\n",
        "\n",
        "def evaluate_global(model):\n",
        "    model.to(device); model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in testloader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            out = model(x); preds = out.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item(); total += x.size(0)\n",
        "    return correct/total if total>0 else 0.0\n",
        "\n",
        "# Aggregators\n",
        "def trimmed_mean_aggregate(client_updates, trim_ratio=0.2):\n",
        "    n_clients = len(client_updates)\n",
        "    trimmed = []\n",
        "    for layer_idx in range(len(client_updates[0])):\n",
        "        stacked = np.stack([client_updates[c][layer_idx].reshape(-1) for c in range(n_clients)], axis=0)\n",
        "        trim_count = int(np.floor(trim_ratio * n_clients))\n",
        "        sorted_vals = np.sort(stacked, axis=0)\n",
        "        if trim_count > 0:\n",
        "            trimmed_vals = sorted_vals[trim_count: n_clients-trim_count, :]\n",
        "        else:\n",
        "            trimmed_vals = sorted_vals\n",
        "        mean_vals = np.mean(trimmed_vals, axis=0)\n",
        "        trimmed.append(mean_vals.reshape(client_updates[0][layer_idx].shape))\n",
        "    return trimmed\n",
        "\n",
        "def fools_gold_weights(client_updates, global_weights, eps=1e-8):\n",
        "    # client_updates: list of client weight lists (numpy arrays)\n",
        "    n = len(client_updates)\n",
        "    # build flatten delta vectors (client_w - global_w)\n",
        "    deltas = []\n",
        "    for c in range(n):\n",
        "        flat = np.concatenate([ (client_updates[c][i] - global_weights[i]).reshape(-1) for i in range(len(global_weights)) ])\n",
        "        deltas.append(flat)\n",
        "    deltas = np.stack(deltas, axis=0)  # shape (n, D)\n",
        "    # compute cosine similarity matrix (n x n)\n",
        "    sims = cosine_similarity(deltas)  # values in [-1,1], diagonal=1\n",
        "    np.fill_diagonal(sims, 0.0)\n",
        "    # for each client, take maximum similarity to any other client\n",
        "    max_sim = sims.max(axis=1)  # shape (n,)\n",
        "    # derive weight = 1 - max_sim (so high-sim => low weight)\n",
        "    raw_w = 1.0 - max_sim\n",
        "    # clip negative to small positive\n",
        "    raw_w = np.clip(raw_w, a_min=eps, a_max=None)\n",
        "    # normalize to sum=1\n",
        "    norm_w = raw_w / raw_w.sum()\n",
        "    return norm_w  # length n, sum=1\n",
        "\n",
        "def aggregate_with_weights(client_updates, weights):\n",
        "    # weights: numpy array shape (n,)\n",
        "    n = len(client_updates)\n",
        "    avg = []\n",
        "    for layer_idx in range(len(client_updates[0])):\n",
        "        accum = np.zeros(client_updates[0][layer_idx].shape, dtype=client_updates[0][layer_idx].dtype)\n",
        "        for i in range(n):\n",
        "            accum += client_updates[i][layer_idx] * weights[i]\n",
        "        avg.append(accum)\n",
        "    return avg\n",
        "\n",
        "# Run baseline (FedAvg) for reference\n",
        "print(\"Running baseline FedAvg (for comparison)...\")\n",
        "global_model = Net().to(device); global_weights = get_weights(global_model)\n",
        "for rnd in range(1, NUM_ROUNDS+1):\n",
        "    client_updates = []; client_ns = []\n",
        "    for i, trainloader in enumerate(client_loaders):\n",
        "        local_model = Net()\n",
        "        is_mal = (i in malicious_client_ids)\n",
        "        local_epochs = ATTACKER_LOCAL_EPOCHS if is_mal else LOCAL_EPOCHS\n",
        "        w, n = local_train_backdoor(local_model, trainloader, global_weights,\n",
        "                                    local_epochs=local_epochs, lr=lr, is_malicious=is_mal, poison_frac=poison_frac)\n",
        "        client_updates.append(w); client_ns.append(n)\n",
        "    # FedAvg average\n",
        "    total_n = sum(client_ns)\n",
        "    avg = []\n",
        "    for li in range(len(client_updates[0])):\n",
        "        accum = np.zeros(client_updates[0][li].shape, dtype=client_updates[0][li].dtype)\n",
        "        for ci in range(len(client_updates)):\n",
        "            accum += client_updates[ci][li] * (client_ns[ci]/total_n)\n",
        "        avg.append(accum)\n",
        "    global_weights = avg; set_weights(global_model, global_weights)\n",
        "    print(f\"Round {rnd} -> acc {evaluate_global(global_model)*100:.2f} %, ASR {compute_asr_backdoor(global_model)*100:.2f}%\")\n",
        "\n",
        "# Trimmed mean sweep\n",
        "trim_values = [0.05, 0.1, 0.2, 0.3]\n",
        "trim_results = {}\n",
        "for trim in trim_values:\n",
        "    print(\"\\nTrim ratio:\", trim)\n",
        "    global_model = Net().to(device); global_weights = get_weights(global_model)\n",
        "    for rnd in range(1, NUM_ROUNDS+1):\n",
        "        client_updates = []; client_ns = []\n",
        "        for i, trainloader in enumerate(client_loaders):\n",
        "            local_model = Net()\n",
        "            is_mal = (i in malicious_client_ids)\n",
        "            local_epochs = ATTACKER_LOCAL_EPOCHS if is_mal else LOCAL_EPOCHS\n",
        "            w, n = local_train_backdoor(local_model, trainloader, global_weights,\n",
        "                                        local_epochs=local_epochs, lr=lr, is_malicious=is_mal, poison_frac=poison_frac)\n",
        "            client_updates.append(w); client_ns.append(n)\n",
        "        avg = trimmed_mean_aggregate(client_updates, trim_ratio=trim)\n",
        "        global_weights = avg; set_weights(global_model, global_weights)\n",
        "        print(f\"Round {rnd} -> acc {evaluate_global(global_model)*100:.2f} %, ASR {compute_asr_backdoor(global_model)*100:.2f}%\")\n",
        "    trim_results[trim] = (evaluate_global(global_model), compute_asr_backdoor(global_model))\n",
        "\n",
        "# FoolsGold-style aggregator (simple round-local version)\n",
        "print(\"\\nRunning FoolsGold-style round-local aggregator...\")\n",
        "global_model = Net().to(device); global_weights = get_weights(global_model)\n",
        "for rnd in range(1, NUM_ROUNDS+1):\n",
        "    client_updates = []; client_ns = []\n",
        "    for i, trainloader in enumerate(client_loaders):\n",
        "        local_model = Net()\n",
        "        is_mal = (i in malicious_client_ids)\n",
        "        local_epochs = ATTACKER_LOCAL_EPOCHS if is_mal else LOCAL_EPOCHS\n",
        "        w, n = local_train_backdoor(local_model, trainloader, global_weights,\n",
        "                                    local_epochs=local_epochs, lr=lr, is_malicious=is_mal, poison_frac=poison_frac)\n",
        "        client_updates.append(w); client_ns.append(n)\n",
        "    # compute FG weights\n",
        "    wgts = fools_gold_weights(client_updates, global_weights)\n",
        "    avg = aggregate_with_weights(client_updates, wgts)\n",
        "    global_weights = avg; set_weights(global_model, global_weights)\n",
        "    print(f\"Round {rnd} -> acc {evaluate_global(global_model)*100:.2f} %, ASR {compute_asr_backdoor(global_model)*100:.2f}%\")\n",
        "\n",
        "print(\"\\nTrim sweep results (final):\")\n",
        "for t,r in trim_results.items():\n",
        "    print(f\"trim {t} -> acc {r[0]*100:.2f}%, ASR {r[1]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWKnCgYBBrIw"
      },
      "outputs": [],
      "source": [
        "# === Plot Accuracy & ASR vs Rounds for FedAvg, TrimmedMean(0.2), and Krum ===\n",
        "import numpy as np\n",
        "import torch, torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Helper functions reused ---\n",
        "@torch.no_grad()\n",
        "def compute_asr_backdoor(model):\n",
        "    model.to(device); model.eval()\n",
        "    correct_target, total = 0, 0\n",
        "    batch_size = 256\n",
        "    for i in range(0, len(triggered_X), batch_size):\n",
        "        xb = triggered_X[i:i+batch_size].to(device)\n",
        "        preds = model(xb).argmax(dim=1)\n",
        "        total += preds.size(0)\n",
        "        correct_target += (preds == target_label).sum().item()\n",
        "    return correct_target / total if total > 0 else 0.0\n",
        "\n",
        "def evaluate_global(model):\n",
        "    model.to(device); model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in testloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            preds = model(x).argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += x.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# --- Aggregators ---\n",
        "def fedavg_aggregate(client_updates, client_ns):\n",
        "    total_n = sum(client_ns)\n",
        "    avg = []\n",
        "    for li in range(len(client_updates[0])):\n",
        "        accum = np.zeros_like(client_updates[0][li])\n",
        "        for ci in range(len(client_updates)):\n",
        "            accum += client_updates[ci][li] * (client_ns[ci]/total_n)\n",
        "        avg.append(accum)\n",
        "    return avg\n",
        "\n",
        "def trimmed_mean_aggregate(client_updates, trim_ratio=0.2):\n",
        "    n = len(client_updates)\n",
        "    trimmed = []\n",
        "    for li in range(len(client_updates[0])):\n",
        "        stacked = np.stack([client_updates[c][li].reshape(-1) for c in range(n)], axis=0)\n",
        "        trim = int(np.floor(trim_ratio*n))\n",
        "        sorted_vals = np.sort(stacked, axis=0)\n",
        "        kept = sorted_vals[trim:n-trim, :] if trim>0 else sorted_vals\n",
        "        mean_vals = np.mean(kept, axis=0)\n",
        "        trimmed.append(mean_vals.reshape(client_updates[0][li].shape))\n",
        "    return trimmed\n",
        "\n",
        "def krum_aggregate(client_updates, f=2):\n",
        "    n = len(client_updates)\n",
        "    flats = [np.concatenate([l.ravel() for l in w]) for w in client_updates]\n",
        "    dmat = np.zeros((n,n))\n",
        "    for i in range(n):\n",
        "        for j in range(i+1,n):\n",
        "            d = np.sum((flats[i]-flats[j])**2)\n",
        "            dmat[i,j]=dmat[j,i]=d\n",
        "    scores=[]\n",
        "    for i in range(n):\n",
        "        closest = np.sort(dmat[i])[:n-f-1]\n",
        "        scores.append(np.sum(closest))\n",
        "    winner = np.argmin(scores)\n",
        "    return client_updates[winner]\n",
        "\n",
        "# --- Run and record results for 3 aggregators ---\n",
        "def run_experiment(agg_name, trim_ratio=0.2):\n",
        "    global_model = Net().to(device)\n",
        "    global_weights = get_weights(global_model)\n",
        "    acc_hist, asr_hist = [], []\n",
        "    for rnd in range(1,6):\n",
        "        client_updates, client_ns = [], []\n",
        "        for i, trainloader in enumerate(client_loaders):\n",
        "            local_model = Net()\n",
        "            is_mal = (i in malicious_client_ids)\n",
        "            local_epochs = ATTACKER_LOCAL_EPOCHS if is_mal else LOCAL_EPOCHS\n",
        "            w, n = local_train_backdoor(local_model, trainloader, global_weights,\n",
        "                                        local_epochs=local_epochs, lr=lr,\n",
        "                                        is_malicious=is_mal, poison_frac=poison_frac)\n",
        "            client_updates.append(w); client_ns.append(n)\n",
        "        if agg_name==\"fedavg\":\n",
        "            global_weights = fedavg_aggregate(client_updates, client_ns)\n",
        "        elif agg_name==\"trimmed_mean\":\n",
        "            global_weights = trimmed_mean_aggregate(client_updates, trim_ratio)\n",
        "        elif agg_name==\"krum\":\n",
        "            global_weights = krum_aggregate(client_updates, f=2)\n",
        "        set_weights(global_model, global_weights)\n",
        "        acc = evaluate_global(global_model)\n",
        "        asr = compute_asr_backdoor(global_model)\n",
        "        acc_hist.append(acc); asr_hist.append(asr)\n",
        "        print(f\"[{agg_name}] Round {rnd}: acc {acc*100:.2f}%, ASR {asr*100:.2f}%\")\n",
        "    return np.array(acc_hist), np.array(asr_hist)\n",
        "\n",
        "histories = {}\n",
        "for name in [\"fedavg\",\"trimmed_mean\",\"krum\"]:\n",
        "    print(f\"\\n=== Running {name} ===\")\n",
        "    histories[name] = run_experiment(name, trim_ratio=0.2 if name==\"trimmed_mean\" else None)\n",
        "\n",
        "# --- Plot ---\n",
        "rounds = np.arange(1,6)\n",
        "plt.figure(figsize=(7,4))\n",
        "for name,c in zip(histories.keys(),[\"r\",\"g\",\"b\"]):\n",
        "    plt.plot(rounds, histories[name][0]*100, marker=\"o\", label=f\"{name} Accuracy\", color=c)\n",
        "plt.xlabel(\"Round\"); plt.ylabel(\"Accuracy (%)\"); plt.title(\"Clean Accuracy vs Rounds\")\n",
        "plt.legend(); plt.grid(True); plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "for name,c in zip(histories.keys(),[\"r\",\"g\",\"b\"]):\n",
        "    plt.plot(rounds, histories[name][1]*100, marker=\"o\", label=f\"{name} ASR\", color=c)\n",
        "plt.xlabel(\"Round\"); plt.ylabel(\"ASR (%)\"); plt.title(\"Backdoor Attack Success Rate vs Rounds\")\n",
        "plt.legend(); plt.grid(True); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1pNbZWsJhhF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
